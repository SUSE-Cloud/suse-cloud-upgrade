#!/bin/bash
# vim: sw=2 et
#
# Copyright 2014, SUSE
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#  http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

set -e

SUSE_LOGFILE="/var/log/crowbar/upgrade/`basename $0`.log"
source "`dirname $0`/common"
source "`dirname $0`/repos-check"


if test -f "${UPGRADE_DATA_DIR}/pre.run"; then
  die "This script has already been run."
fi


ensure_data_dir
check_crowbar_key_or_fail
suse_cloud_version=$(get_installed_suse_cloud_version)

if test "x$suse_cloud_version" != "x4"; then
  die "Current installed version of SUSE Cloud is not 4: $suse_cloud_version"
fi


echo_summary "Ensuring SUSE Cloud 5 repositories are available..."

# Populate new directory for repos
old_repos_dir=/srv/tftpboot/repos
repos_dir=/srv/tftpboot/suse-11.3/repos
repos12_dir=/srv/tftpboot/suse-12.0/repos

mkdir -p $repos_dir
mkdir -p $repos12_dir

# Automatically create symlinks for new SMT-mirrored repos if they exist
for repo in SUSE-Cloud-5-Pool \
            SUSE-Cloud-5-Updates; do
  cloud_dir=$repos_dir/$repo
  smt_dir=/srv/www/htdocs/repo/\$RCE/$repo/sle-11-x86_64
  test ! -e $cloud_dir -a -d $smt_dir && ln -s $smt_dir $cloud_dir
done

# For SLE repos, try to re-use the same setup as before, or fallback to
# symlinks to SMT-mirrored repos
for repo in SLES11-SP3-Pool \
            SLES11-SP3-Updates \
            SLE11-HAE-SP3-Pool \
            SLE11-HAE-SP3-Updates; do
  cloud_dir=$repos_dir/$repo
  smt_dir=/srv/www/htdocs/repo/\$RCE/$repo/sle-11-x86_64

  test -e $cloud_dir && continue

  if test -L $old_repos_dir/$repo -a -d "$(readlink $old_repos_dir/$repo)"; then
    ln -s "$(readlink $old_repos_dir/$repo)" $cloud_dir
  elif test -d $old_repos_dir/$repo; then
    ln -s $old_repos_dir/$repo $cloud_dir
  elif test -d $smt_dir; then
    ln -s $smt_dir $cloud_dir
  fi
done

# Create symlinks for the SLE12 SMT-mirrored repos if they exist
cloud_dir=$repos12_dir/SLES12-Pool
smt_dir=/srv/www/htdocs/repo/SUSE/Products/SLE-SERVER/12/x86_64/product
test ! -e $cloud_dir -a -d $smt_dir && ln -s $smt_dir $cloud_dir

cloud_dir=$repos12_dir/SLES12-Updates
smt_dir=/srv/www/htdocs/repo/SUSE/Updates/SLE-SERVER/12/x86_64/update
test ! -e $cloud_dir -a -d $smt_dir && ln -s $smt_dir $cloud_dir

cloud_dir=$repos12_dir/SLE-12-Cloud-Compute5-Pool
smt_dir=/srv/www/htdocs/repo/SUSE/Products/12-Cloud-Compute/5/x86_64/product
test ! -e $cloud_dir -a -d $smt_dir && ln -s $smt_dir $cloud_dir

cloud_dir=$repos12_dir/SLE-12-Cloud-Compute5-Updates
smt_dir=/srv/www/htdocs/repo/SUSE/Updates/12-Cloud-Compute/5/x86_64/update
test ! -e $cloud_dir -a -d $smt_dir && ln -s $smt_dir $cloud_dir

cloud_dir=$repos12_dir/SUSE-Enterprise-Storage-1.0-Pool
smt_dir=/srv/www/htdocs/repo/SUSE/Products/Storage/1.0/x86_64/product
test ! -e $cloud_dir -a -d $smt_dir && ln -s $smt_dir $cloud_dir

cloud_dir=$repos12_dir/SUSE-Enterprise-Storage-1.0-Updates
smt_dir=/srv/www/htdocs/repo/SUSE/Updates/Storage/1.0/x86_64/update
test ! -e $cloud_dir -a -d $smt_dir && ln -s $smt_dir $cloud_dir


echo_summary "Performing sanity checks..."


### Check that we can talk to crowbar
out=$(crowbar crowbar list)
if test "x$out" != "xdefault"; then
  die "Unexpected results when checking for communication with Crowbar server."
fi


### Check that /etc/crowbar/provisioner.json contains updated info about repositories
mkdir -p "${UPGRADE_DATA_DIR}/provisioner"
OLD_PROVISIONER_JSON="${UPGRADE_DATA_DIR}/provisioner/default-4.json"
ETC_PROVISIONER_JSON="/etc/crowbar/provisioner.json"
crowbar provisioner proposal show default > "$OLD_PROVISIONER_JSON"

# Check that /etc/crowbar/provisioner.json contains the minimum bits we need...
all_repos=
missing_repos=
for repo in SLE-Cloud SLE-Cloud-PTF SLES11-SP-{Pool,Updates} SLE11-HAE-SP3-{Pool,Updates} SUSE-Cloud-4-{Pool,Updates}; do
  if test -n "`get_repo_url_from "$repo" "$OLD_PROVISIONER_JSON"`"; then
    all_repos="$all_repos $repo"
    if test ! -f "$ETC_PROVISIONER_JSON"; then
      missing_repos="$missing_repos $repo"
    elif test -z "`get_repo_url_from "${repo//Cloud-4/Cloud-5}" "$ETC_PROVISIONER_JSON"`"; then
      missing_repos="$missing_repos $repo"
    fi
  fi
done

if test -n "$missing_repos"; then
  if test ! -f "$ETC_PROVISIONER_JSON"; then
    die "\nThe current provisioner configuration uses the following repositories:\n  ${all_repos}\nFor the upgrade process, please create a $ETC_PROVISIONER_JSON file with the following repositories:\n  ${all_repos//Cloud-4/Cloud-5}"
  else
    die "\nThe current provisioner configuration uses the following repositories:\n  ${all_repos}\nFor the upgrade process, please update $ETC_PROVISIONER_JSON so that it contains the following repositories:\n  ${all_repos//Cloud-4/Cloud-5}\n(Following repositories are missing:${missing_repos//Cloud-4/Cloud-5})"
  fi
fi

# ... and check that /etc/crowbar/provisioner.json doesn't contain more than
# what we need (adding Cloud 5 repo is fine, but adding other repos: we're not
# sure if it's an error or not)
if test -f "$ETC_PROVISIONER_JSON"; then
  all_repos=
  missing_repos=
  for repo in SLE-Cloud SLE-Cloud-PTF SLES11-SP3-{Pool,Updates} SLE11-HAE-SP3-{Pool,Updates}; do
    if test -n "`get_repo_url_from "$repo" "$ETC_PROVISIONER_JSON"`"; then
      all_repos="$all_repos $repo"
      if test -z "`get_repo_url_from "${repo}" "$OLD_PROVISIONER_JSON"`"; then
        missing_repos="$missing_repos $repo"
      fi
    fi
  done

  if test -n "$missing_repos"; then
    msg="\n$ETC_PROVISIONER_JSON contains the following repositories:\n  ${all_repos}\nHowever, the current provisioner configuration does not contain these repositories:\n  ${missing_repos}\n\nIf you continue with the upgrade process, the missing repositories will automatically be added to the provisioner configuration.\nIf needed, you can stop the upgrade process now and update $ETC_PROVISIONER_JSON to remove repositories.\n\nDo you want to continue?"
    if ! ask_yes_no_default_no "$msg"; then
      exit 0
    fi
  fi

  # Skip the repository checks if they are defined in provisioner.json:
  # there might be non-default (and/or network) path
  for repo in SLE-Cloud SUSE-Cloud-5-Pool SUSE-Cloud-5-Updates; do
    # json_read is part of crowbar package
    common_check="$( json_read $PROVISIONER_JSON attributes.provisioner.suse.autoyast.repos.common.${repo//./\\\\.}.url )"
    sles11_check="$( json_read $PROVISIONER_JSON attributes.provisioner.suse.autoyast.repos.suse-11\\.3.${repo//./\\\\.}.url )"

    if [ -n "$common_check" -o -n "$sles11_check" ]; then
      REPOS_SKIP_CHECKS+=" ${repo#SLE-}"
    fi
  done
fi

# also check that updating the provisioner proposal works (and there's no
# invalid data)
if test -f "$ETC_PROVISIONER_JSON"; then
  if ! crowbar pacemaker proposal edit default --file "$OLD_PROVISIONER_JSON"; then
    die "The provisioner proposal cannot be automatically edited.\nMake sure that the current proposal is valid (by editing and saving it)!"
  fi
fi


### Check if repositories are prepared for the upgrade
# We need to ensure that Cloud5 main repository and update repos are in place

check_media_content \
    Cloud \
    /srv/tftpboot/suse-11.3/repos/Cloud \
    #1558be86e7354d31e71e7c8c2574031a

# This is the check for repositories available for the nodes
check_repo_tag summary 11.3 SUSE-Cloud-5-Pool      'SUSE Cloud 5'
#check_repo_tag repo    11.3 SUSE-Cloud-5-Updates   'updates://zypp-patches.suse.de/autobuild/SUSE_CLOUD/5/update/x86_64'
check_repo_tag key     11.3 SUSE-Cloud-5-Updates

# Now, check if NCC provides Cloud-5 repositories for the admin server
for repo in SUSE-Cloud-5-Pool SUSE-Cloud-5-Updates; do
  if ! grep -q "$repo" /etc/zypp/repos.d/*; then
    die "Repository $repo does not seem to be configured on the admin server.\nIs the SUSE Cloud 5 product correctly registered?"
  fi
done


### Check that all installed barclamps are from SUSE Cloud
unknown_barclamps=
for yml in /opt/dell/crowbar_framework/barclamps/*.yml; do
  base=$(basename $yml)
  barclamp=${base%%.yml}
  case $barclamp in
    crowbar|deployer|dns|ipmi|logging|network|ntp|provisioner|pacemaker|\
    database|rabbitmq|openstack|keystone|swift|ceph|glance|cinder|neutron|nova|\
    nova_dashboard|updater|suse_manager_client|nfs_client|cisco_ucs|hyperv|heat|ceilometer|\
    trove|tempest)
      ;;
    *)
      unknown_barclamps="$unknown_barclamps $barclamp"
      ;;
  esac
done

if test -n "$unknown_barclamps"; then
  die "The following barclamps need to be manually deinstalled before the upgrade\nprocess (and can be reinstalled after the upgrade):\n  $unknown_barclamps"
fi


### Check that all nodes are powered on
get_allocated_nodes
allocated_nodes=$get_allocated_nodes_retval

for node in $allocated_nodes; do
  if ! ssh "$node" true 2> /dev/null; then
    die "Cannot reach $node; all allocated nodes must be powered on!"
  fi
done


### Find out HA cluster information
get_cluster_founders
cluster_founders=$get_cluster_founders_retval


## Check if pacemaker cluster's health is good
echo_summary "Checking health of HA clusters..."
failed_actions_founders=
for founder in $cluster_founders; do
  if ssh ${founder} 'LANG=C crm status | grep -q "^Failed actions:"'; then
    failed_actions_founders="${failed_actions_founders}$founder "
  fi
done
if [ -n "$failed_actions_founders" ] ; then
  die "'crm status' command reports some failed actions on the clusters that the following nodes are part of: $failed_actions_founders\nClean pacemaker resources using 'crm resource cleanup' before proceeding with the upgrade."
fi


### Get all nodes with the neutron-l3 role before we deactivate the proposals
get_allocated_nodes neutron-l3
allocated_neutron_l3_nodes=$get_allocated_nodes_retval


### Deactivate all proposals
echo_summary "Deactivating OpenStack barclamp proposals..."

deactivation_list="trove tempest heat ceilometer nova_dashboard nova neutron cinder glance ceph swift keystone rabbitmq database pacemaker"

for barclamp in $deactivation_list; do
  if [ ! -f "/opt/dell/crowbar_framework/barclamps/$barclamp.yml" ]; then
    echo "Skipping deactivation of $barclamp barclamp."
    continue
  fi

  applied_proposals=$(crowbar "$barclamp" list)
  if test "$applied_proposals" == "No current configurations"; then
    continue
  fi

  for proposal in $applied_proposals; do
    echo "Deactivating proposal $proposal of barclamp ${barclamp}..."
    crowbar "$barclamp" delete "$proposal"
  done
done

# Double-check there's nothing left; we do another loop to avoid a race where
# the proposal is still listed, just after we deleted it
sleep 10

for barclamp in $deactivation_list; do
  if [ ! -f "/opt/dell/crowbar_framework/barclamps/$barclamp.yml" ]; then
    continue
  fi

  applied_proposals=$(crowbar "$barclamp" list)
  if test "$applied_proposals" != "No current configurations"; then
    die "Was not able to deactivate all proposals for $barclamp."
  fi
done

# Stop chef-clients at the nodes, to ensure services shutdown in next step won't be started by chef
for node in $allocated_nodes; do
  echo "Stopping chef-client service on ${node}..."
  ssh "$node" 'rcchef-client stop'
done


### Stop pacemaker resources in all clusters and put the nodes into standby mode
echo_summary "Stopping pacemaker resources..."

for founder in $cluster_founders; do
  echo "Stopping crm resources on ${founder}..."
  ssh "$founder" '
    for type in clone ms primitive; do
      for resource in $(crm configure show | grep ^$type | cut -d " " -f2); do
        crm resource stop $resource
      done
    done
    '
done


### Stop openstack services
echo_summary "Stopping OpenStack services..."

for node in $allocated_nodes; do
  echo "Disabling OpenStack services on ${node}..."
  ssh "$node" 'for i in /etc/init.d/openstack-* /etc/init.d/openvswitch-switch /etc/init.d/ovs-usurp-config-* /etc/init.d/drbd /etc/init.d/openais; do if test -e $i ; then initscript=`basename $i`; chkconfig -d $initscript; $i stop; fi; done'
done


### Workaround for neutron shortcoming
# Currently neutron-ns-metadata-proxy is not stoppend on a HA setup. The running process
# kills the update, so we need to kill it manually. Upstream is working on improving the
# handling of external processes. Once this is achieved we don't need this part anymore
# Defining allocated_neutron_l3_nodes earlier is connected to this

for node in $allocated_neutron_l3_nodes; do
  echo "Killing neutron-ns-metadata-proxy process on $node..."
  ssh "$node" 'killall -q neutron-ns-metadata-proxy || true'
done

# Make sure all openstack services are down on all nodes before we stop rabbitmq
services_stopped=""
count=0
while [ "$services_stopped" != "yes" -a "$count" -lt 100 ]; do
  echo "Waiting for OpenStack services to stop..."
  sleep 1
  services_stopped="yes"
  for node in $allocated_nodes; do
    if ssh "$node" 'shopt -s nullglob
      for i in /etc/init.d/openstack-* ; do
        if [ "$i" == /etc/init.d/openstack-neutron-ovs-cleanup ]; then
          continue
        fi
        if $i status >/dev/null ; then
          echo "$i still running at `hostname`"; exit 0
        fi
      done
      exit 1'; then
      services_stopped="no"
      break
    fi
  done
  count=$(($count + 1))
done
if [ "$services_stopped" == "no" ]; then
  echo "Some OpenStack services didn't finish in time, timeout reached."
fi

# Note: be careful that this is not run on the admin node, where we need rabbitmq!
for node in $allocated_nodes; do
  ssh "$node" 'if test -f /etc/init.d/rabbitmq-server; then chkconfig -d rabbitmq-server; /etc/init.d/rabbitmq-server stop; fi'
done


### Update the repos on each node
echo_summary "Disabling SUSE Cloud 4 repositories..."
for node in $allocated_nodes; do
  echo "Updating repositories on ${node}..."
  ssh "$node" 'zypper mr -d SUSE-Cloud-4-Pool SUSE-Cloud-4-Updates'
done


### Disable crowbar and chef-client while packages get upgraded
echo_summary "Stopping Crowbar..."
# Stop the looper, so it'll get upgraded too
pkill -f /opt/dell/bin/looper_chef_client.sh || true

rcchef-client stop
rccrowbar stop
rm /opt/dell/crowbar_framework/.crowbar-installed-ok

rcchef-server stop
rcchef-expander stop
rcchef-solr stop
rccouchdb stop
rcrabbitmq-server stop
# try to stop epmd which still runs after we stop rabbitmq; we need a sleep to
# ensure that the rabbitmq bit is unregistered
sleep 5
if which rcepmd &> /dev/null; then
  rcepmd stop
else
  epmd -kill || true
fi


### Done
touch "${UPGRADE_DATA_DIR}/pre.run"
